import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import os
from unidecode import unidecode
from gtts import gTTS
import base64

# --- C·∫§U H√åNH MEDIAPIPE ---
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# --- H√ÄM H·ªñ TR·ª¢ ---
def get_audio_html(text):
    """T·∫°o √¢m thanh ti·∫øng Vi·ªát ƒë·ªÉ ph√°t tr√™n tr√¨nh duy·ªát"""
    try:
        tts = gTTS(text=f"C√¢u n√≥i l√†: {text}", lang='vi')
        tts.save("temp_audio.mp3")
        with open("temp_audio.mp3", "rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode()
            return f'<audio autoplay="true" src="data:audio/mp3;base64,{b64}">'
    except:
        return ""

def search_file(name, category):
    """T√¨m ki·∫øm file video ho·∫∑c ·∫£nh d·ª±a tr√™n t√™n v√† ch·ªß ƒë·ªÅ"""
    name_clean = unidecode(name).lower().strip()
    folders = ["video_train", "anh_train", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"]
    
    if category != "T·∫•t c·∫£":
        folders = [category]

    for folder in folders:
        if os.path.exists(folder):
            for file in os.listdir(folder):
                file_no_ext = unidecode(os.path.splitext(file)[0]).lower().strip()
                if name_clean == file_no_ext:
                    return os.path.join(folder, file)
    return None

# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="NG√îN NG·ªÆ K√ù HI·ªÜU AI", layout="wide")
st.title("ü§ü H·ªá Th·ªëng Ng√¥n Ng·ªØ K√Ω Hi·ªáu AI")

col_left, col_right = st.columns([2, 1])

with col_left:
    st.subheader("üì∑ Camera Nh·∫≠n Di·ªán")
    run_cam = st.toggle("B·∫≠t Camera")
    FRAME_WINDOW = st.image([])

    if run_cam:
        cap = cv2.VideoCapture(0)
        while run_cam:
            ret, frame = cap.read()
            if not ret:
                st.error("Kh√¥ng th·ªÉ truy c·∫≠p Camera.")
                break
            
            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = hands.process(rgb_frame)

            # V·∫Ω k·∫øt qu·∫£ nh·∫≠n di·ªán tay
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(
                        rgb_frame, 
                        hand_landmarks, 
                        mp_hands.HAND_CONNECTIONS
                    )
            
            FRAME_WINDOW.image(rgb_frame)
        cap.release()

with col_right:
    st.subheader("üîç Tra c·ª©u")
    search_query = st.text_input("Nh·∫≠p ch·ªØ c√°i ho·∫∑c t·ª´ kh√≥a:")
    category_option = st.selectbox("Ch·ªß ƒë·ªÅ:", 
        ["T·∫•t c·∫£", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"])
    
    if st.button("T√¨m ki·∫øm"):
        if search_query:
            result_path = search_file(search_query, category_option)
            if result_path:
                st.success(f"K·∫øt qu·∫£ cho: {search_query}")
                if result_path.lower().endswith(('.mp4', '.avi', '.mkv')):
                    st.video(result_path)
                else:
                    st.image(result_path)
                # Ph√°t √¢m thanh
                st.components.v1.html(get_audio_html(search_query), height=0)
            else:
                st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu.")
