import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import os
from PIL import Image
from unidecode import unidecode
from gtts import gTTS
import base64

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="NG√îN NG·ªÆ K√ù HI·ªÜU AI", layout="wide")
st.title("ü§ü H·ªá Th·ªëng H·ªçc Ng√¥n Ng·ªØ K√Ω Hi·ªáu AI")

# --- KH·ªûI T·∫†O MEDIAPIPE ---
mp_hands = mp.solutions.hands [cite: 14]
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) [cite: 15]
mp_drawing = mp.solutions.drawing_utils [cite: 24]

# --- H√ÄM H·ªñ TR·ª¢ ---
def get_audio_html(text, lang='vi'):
    """T·∫°o HTML ƒë·ªÉ t·ª± ƒë·ªông ph√°t √¢m thanh gTTS tr√™n tr√¨nh duy·ªát"""
    tts = gTTS(text=text, lang=lang)
    tts.save("temp_audio.mp3")
    with open("temp_audio.mp3", "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        return f'<audio autoplay="true" src="data:audio/mp3;base64,{b64}">'

def process_frame(frame):
    """X·ª≠ l√Ω khung h√¨nh ƒë·ªÉ v·∫Ω landmarks"""
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) [cite: 73]
    results = hands.process(image_rgb) [cite: 76]
    
    if results.multi_hand_landmarks: [cite: 89]
        for hand_landmarks in results.multi_hand_landmarks: [cite: 90]
            mp_drawing.draw_landmarks(
                frame, 
                hand_landmarks, 
                mp_hands.HAND_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2), [cite: 27]
                mp_drawing.DrawingSpec(color=(200, 0, 0), thickness=2, circle_radius=2) [cite: 28]
            )
    return frame

# --- GIAO DI·ªÜN SIDEBAR (T√åM KI·∫æM) ---
st.sidebar.header("üîç T√¨m ki·∫øm k√Ω hi·ªáu")
search_query = st.sidebar.text_input("Nh·∫≠p c√¢u n√≥i ho·∫∑c ch·ªØ c√°i:") [cite: 165, 167]
chude_option = st.sidebar.selectbox("Ch·ªß ƒë·ªÅ:", 
    ["T·∫•t c·∫£", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"]) [cite: 178, 180, 181, 182, 183, 184]

if st.sidebar.button("T√¨m ki·∫øm"): [cite: 169]
    found = False
    name_clean = unidecode(search_query).lower().strip() [cite: 31]
    
    # Logic qu√©t th∆∞ m·ª•c t·ª´ m√£ g·ªëc [cite: 33, 35, 47]
    folders = ["video_train", "anh_train", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"]
    if chude_option != "T·∫•t c·∫£":
        folders = [chude_option]

    for folder in folders:
        if os.path.exists(folder):
            for file in os.listdir(folder):
                if unidecode(os.path.splitext(file)[0]).lower() == name_clean:
                    file_path = os.path.join(folder, file) [cite: 53]
                    st.write(f"K·∫øt qu·∫£ cho: **{search_query}**")
                    
                    if file.lower().endswith(('.mp4', '.avi', '.mkv')): [cite: 54]
                        st.video(file_path) [cite: 55]
                    else:
                        st.image(file_path) [cite: 57]
                    
                    # Ph√°t √¢m thanh th√¥ng b√°o
                    st.components.v1.html(get_audio_html(f"K·∫øt qu·∫£ c·ªßa {search_query}"), height=0)
                    found = True
                    break
    if not found:
        st.sidebar.error("Kh√¥ng t√¨m th·∫•y ng√¥n ng·ªØ k√Ω hi·ªáu ph√π h·ª£p") [cite: 61]

# --- GIAO DI·ªÜN CH√çNH (NH·∫¨N DI·ªÜN CAMERA) ---
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("üì∑ Nh·∫≠n di·ªán tr·ª±c ti·∫øp")
    run_camera = st.checkbox("B·∫≠t Camera nh·∫≠n di·ªán") [cite: 173]
    FRAME_WINDOW = st.image([])

    if run_camera:
        cap = cv2.VideoCapture(0) [cite: 64]
        while run_camera:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            frame = process_frame(frame)
            frame_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            FRAME_WINDOW.image(frame_display)
        cap.release()
    else:
        st.info("Nh·∫•n d·∫•u t√≠ch ·ªü tr√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán tay qua Camera.")

with col2:
    st.subheader("üí° H∆∞·ªõng d·∫´n & Ghi ch√∫")
    st.markdown("""
    - **ƒÇ, √Ç, √ä, √î...**: K·∫øt h·ª£p ch·ªØ c√°i g·ªëc v√† v·∫Ω d·∫•u trong khung h√¨nh.
    - **Ph√¢n bi·ªát S·ªë/Ch·ªØ**: H·ªá th·ªëng s·∫Ω d·ª±a v√†o th·ªùi gian gi·ªØ tay (Hold time) ho·∫∑c ch·∫ø ƒë·ªô ch·ªçn.
    - **Gi·ªçng n√≥i**: B·∫°n c√≥ th·ªÉ d√πng bi·ªÉu t∆∞·ª£ng micro tr√™n b√†n ph√≠m ƒëi·ªán tho·∫°i/m√°y t√≠nh ƒë·ªÉ nh·∫≠p v√†o √¥ t√¨m ki·∫øm.
    """)
    
    # Upload video ƒë·ªÉ ph√¢n t√≠ch [cite: 149, 150]
    uploaded_file = st.file_uploader("Ho·∫∑c t·∫£i l√™n video ƒë·ªÉ ph√¢n t√≠ch", type=['mp4', 'avi', 'mkv'])
    if uploaded_file is not None:
        st.video(uploaded_file)
        st.success(f"ƒê√£ t·∫£i l√™n: {uploaded_file.name}")
