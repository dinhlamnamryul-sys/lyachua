import streamlit as st
import cv2
import mediapipe as mp
import av
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="H·ªá th·ªëng NNKH AI",
    page_icon="üëê",
    layout="wide"
)

# --- D·ªÆ LI·ªÜU GI·∫¢ L·∫¨P ---
mock_library = [
    {"id": 1, "name": "Xin ch√†o", "category": "gia ƒë√¨nh", "type": "video", "url": "https://www.w3schools.com/html/mov_bbb.mp4"},
    {"id": 2, "name": "Qu·∫£ t√°o", "category": "tr√°i c√¢y", "type": "image", "url": "https://images.unsplash.com/photo-1560806887-1e4cd0b6bcd6?w=400"},
    {"id": 3, "name": "B√∫t ch√¨", "category": "ƒë·ªì d√πng h·ªçc t·∫≠p", "type": "image", "url": "https://images.unsplash.com/photo-1512036667332-2323862660f9?w=400"},
    {"id": 4, "name": "Con m√®o", "category": "ƒë·ªông v·∫≠t", "type": "video", "url": "https://www.w3schools.com/html/movie.mp4"},
    {"id": 5, "name": "√î t√¥", "category": "giao th√¥ng", "type": "image", "url": "https://images.unsplash.com/photo-1494976388531-d1058494cdd8?w=400"},
]

categories = ["T·∫•t c·∫£", "Gia ƒë√¨nh", "Tr√°i c√¢y", "ƒê·ªì d√πng h·ªçc t·∫≠p", "ƒê·ªông v·∫≠t", "Giao th√¥ng"]

# --- CLASS X·ª¨ L√ù VIDEO AI (MEDIAPIPE) ---
class HandDetectorProcessor(VideoTransformerBase):
    def __init__(self):
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.hands.process(img_rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                self.mp_drawing.draw_landmarks(
                    img, 
                    hand_landmarks, 
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                    self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
                )
            cv2.putText(img, "AI DANG QUET...", (30, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        else:
             cv2.putText(img, "HAY GIO TAY LEN...", (30, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return img

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üëê H·ªá th·ªëng Ng√¥n ng·ªØ K√Ω hi·ªáu AI")

tab1, tab2 = st.tabs(["üìö Th∆∞ vi·ªán h·ªçc t·∫≠p", "üì∑ Nh·∫≠n di·ªán AI"])

# TAB 1: TH∆Ø VI·ªÜN
with tab1:
    col1, col2 = st.columns([1, 2])
    with col1:
        st.subheader("Tra c·ª©u")
        search_term = st.text_input("Nh·∫≠p t·ª´ kh√≥a:")
        selected_cat = st.selectbox("Ch·ªçn danh m·ª•c:", categories)
        search_btn = st.button("T√¨m ki·∫øm")

    with col2:
        if search_btn or search_term:
            filtered = [i for i in mock_library if search_term.lower() in i['name'].lower()]
            if filtered:
                item = filtered[0]
                st.info(f"ƒêang hi·ªÉn th·ªã: {item['name']}")
                if item['type'] == 'video':
                    st.video(item['url'])
                else:
                    st.image(item['url'])
            else:
                st.error("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£.")
        else:
            st.write("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ xem h∆∞·ªõng d·∫´n k√Ω hi·ªáu.")

# TAB 2: NH·∫¨N DI·ªÜN
with tab2:
    st.subheader("Nh·∫≠n di·ªán tay th·ªùi gian th·ª±c")
    st.write("Nh·∫•n Start ƒë·ªÉ b·∫Øt ƒë·∫ßu. H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng AI MediaPipe ƒë·ªÉ qu√©t c√°c kh·ªõp ng√≥n tay c·ªßa b·∫°n.")
    
    webrtc_streamer(
        key="hand-detection-app",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=HandDetectorProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

st.markdown("---")
st.caption("·ª®ng d·ª•ng ch·∫°y tr√™n n·ªÅn t·∫£ng Streamlit & MediaPipe")
