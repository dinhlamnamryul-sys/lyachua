import streamlit as st
import cv2
import mediapipe as mp
import av
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="H·ªá th·ªëng NNKH AI",
    page_icon="üëê",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- D·ªÆ LI·ªÜU GI·∫¢ L·∫¨P (MOCK DATA) ---
mock_library = [
    {"id": 1, "name": "Xin ch√†o", "category": "gia ƒë√¨nh", "type": "video", "url": "https://www.w3schools.com/html/mov_bbb.mp4"},
    {"id": 2, "name": "Qu·∫£ t√°o", "category": "tr√°i c√¢y", "type": "image", "url": "https://images.unsplash.com/photo-1560806887-1e4cd0b6bcd6?w=400"},
    {"id": 3, "name": "B√∫t ch√¨", "category": "ƒë·ªì d√πng h·ªçc t·∫≠p", "type": "image", "url": "https://images.unsplash.com/photo-1512036667332-2323862660f9?w=400"},
    {"id": 4, "name": "Con m√®o", "category": "ƒë·ªông v·∫≠t", "type": "video", "url": "https://www.w3schools.com/html/movie.mp4"},
    {"id": 5, "name": "√î t√¥", "category": "giao th√¥ng", "type": "image", "url": "https://images.unsplash.com/photo-1494976388531-d1058494cdd8?w=400"},
]

categories = ["T·∫•t c·∫£", "Gia ƒë√¨nh", "Tr√°i c√¢y", "ƒê·ªì d√πng h·ªçc t·∫≠p", "ƒê·ªông v·∫≠t", "Giao th√¥ng"]

# --- CLASS X·ª¨ L√ù VIDEO AI (MEDIAPIPE) ---
class HandDetectorProcessor(VideoTransformerBase):
    def __init__(self):
        # Kh·ªüi t·∫°o MediaPipe Hands
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

    def transform(self, frame):
        # Chuy·ªÉn ƒë·ªïi khung h√¨nh t·ª´ WebRTC sang ƒë·ªãnh d·∫°ng OpenCV
        img = frame.to_ndarray(format="bgr24")
        
        # L·∫≠t ng∆∞·ª£c ·∫£nh cho gi·ªëng g∆∞∆°ng
        img = cv2.flip(img, 1)
        
        # Chuy·ªÉn sang RGB ƒë·ªÉ MediaPipe x·ª≠ l√Ω
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.hands.process(img_rgb)

        # V·∫Ω Landmarks n·∫øu ph√°t hi·ªán tay
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # V·∫Ω khung x∆∞∆°ng tay
                self.mp_drawing.draw_landmarks(
                    img, 
                    hand_landmarks, 
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                    self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
                )
                
            # Hi·ªÉn th·ªã th√¥ng b√°o tr·∫°ng th√°i l√™n video
            cv2.putText(img, "AI DANG QUET...", (30, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.rectangle(img, (20, 20), (280, 70), (0, 255, 0), 2)
        else:
             cv2.putText(img, "HAY GIO TAY LEN...", (30, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return img

# --- GIAO DI·ªÜN CH√çNH (SIDEBAR) ---
st.sidebar.title("üëê H·ªá th·ªëng NNKH")
active_view = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng:", ["üìö Th∆∞ vi·ªán h·ªçc t·∫≠p", "üì∑ Nh·∫≠n di·ªán AI"])

st.sidebar.info("Phi√™n b·∫£n Streamlit Python - T√≠ch h·ª£p MediaPipe th·∫≠t.")

# --- VIEW 1: TH∆Ø VI·ªÜN H·ªåC T·∫¨P ---
if active_view == "üìö Th∆∞ vi·ªán h·ªçc t·∫≠p":
    st.title("üìö Tra c·ª©u Ng√¥n ng·ªØ k√Ω hi·ªáu")
    
    # Khu v·ª±c t√¨m ki·∫øm
    col1, col2 = st.columns([2, 1])
    with col1:
        search_term = st.text_input("üîç Nh·∫≠p t√™n k√Ω hi·ªáu:", placeholder="V√≠ d·ª•: Xin ch√†o, Qu·∫£ t√°o...")
    with col2:
        selected_cat = st.selectbox("üìÇ Danh m·ª•c:", categories)

    # Logic l·ªçc d·ªØ li·ªáu
    filtered_items = []
    for item in mock_library:
        matches_search = search_term.lower() in item['name'].lower()
        matches_cat = selected_cat == "T·∫•t c·∫£" or item['category'].lower() == selected_cat.lower()
        
        if matches_search and matches_cat:
            filtered_items.append(item)

    st.markdown("---")

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    if search_term: # Ch·ªâ hi·ªán khi ng∆∞·ªùi d√πng t√¨m ki·∫øm ho·∫∑c ch·ªçn
        if filtered_items:
            item = filtered_items[0] # L·∫•y k·∫øt qu·∫£ ƒë·∫ßu ti√™n t√¨m th·∫•y
            
            c1, c2 = st.columns([2, 1])
            with c1:
                st.subheader(f"K·∫øt qu·∫£: {item['name']}")
                
                if item['type'] == 'video':
                    st.video(item['url'])
                else:
                    st.image(item['url'], use_container_width=True)
            
            with c2:
                st.write(f"**Danh m·ª•c:** {item['category']}")
                st.info(f"üîä ƒêang ph√°t √¢m thanh: '{item['name']}'")
                # Trong Python Streamlit, TTS ph·ª©c t·∫°p h∆°n, ta d√πng th√¥ng b√°o gi·∫£ l·∫≠p
                st.success("M√¥ ph·ªèng: √Çm thanh ƒë√£ ƒë∆∞·ª£c ph√°t.")
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o ph√π h·ª£p.")
    else:
        st.info("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ t√¨m ki·∫øm.")
        # Hi·ªÉn th·ªã l∆∞·ªõi g·ª£i √Ω
        st.subheader("G·ª£i √Ω ph·ªï bi·∫øn:")
        cols = st.columns(3)
        for idx, item in enumerate(mock_library[:3]):
            with cols[idx]:
                if item['type'] == 'image':
                    st.image(item['url'], caption=item['name'], use_container_width=True)
                else:
                    st.video(item['url'])
                    st.caption(item['name'])

# --- VIEW 2: NH·∫¨N DI·ªÜN AI ---
elif active_view == "üì∑ Nh·∫≠n di·ªán AI":
    st.title("üì∑ Camera Nh·∫≠n di·ªán (Real-time)")
    
    col_cam, col_info = st.columns([3, 1])
    
    with col_cam:
        st.write("B·∫≠t camera ƒë·ªÉ h·ªá th·ªëng b·∫Øt ƒë·∫ßu qu√©t tay:")
        
        # Component WebRTC thay th·∫ø cho video tag c·ªßa HTML5
        ctx = webrtc_streamer(
            key="hand-detection",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=HandDetectorProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    with col_info:
        st.markdown("### Tr·∫°ng th√°i")
        if ctx.state.playing:
            st.success("Camera ƒëang b·∫≠t")
            st.info("AI ƒëang ph√¢n t√≠ch khung h√¨nh...")
        else:
            st.warning("Camera ƒëang t·∫Øt")
            
        st.markdown("---")
        st.metric(label="D·ª± ƒëo√°n hi·ªán t·∫°i", value="---")
        
        st.warning(
            """
            **H∆∞·ªõng d·∫´n:**
            1. Nh·∫•n n√∫t "START" b√™n d∆∞·ªõi camera.
            2. Cho ph√©p tr√¨nh duy·ªát truy c·∫≠p Webcam.
            3. Gi∆° tay l√™n tr∆∞·ªõc camera ƒë·ªÉ th·∫•y khung x∆∞∆°ng tay ƒë∆∞·ª£c v·∫Ω.
            """
        )

# Footer
st.markdown("---")
st.markdown("<center>Ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è b·∫±ng Streamlit & MediaPipe</center>", unsafe_allow_html=True)
