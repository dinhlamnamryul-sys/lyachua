import streamlit as st
import cv2
import mediapipe as mp
import av
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="H·ªá th·ªëng NNKH AI",
    page_icon="üëê",
    layout="wide"
)

# --- D·ªÆ LI·ªÜU GI·∫¢ L·∫¨P ---
mock_library = [
    {"id": 1, "name": "Xin ch√†o", "category": "gia ƒë√¨nh", "type": "video", "url": "https://www.w3schools.com/html/mov_bbb.mp4"},
    {"id": 2, "name": "Qu·∫£ t√°o", "category": "tr√°i c√¢y", "type": "image", "url": "https://images.unsplash.com/photo-1560806887-1e4cd0b6bcd6?w=400"},
    {"id": 3, "name": "B√∫t ch√¨", "category": "ƒë·ªì d√πng h·ªçc t·∫≠p", "type": "image", "url": "https://images.unsplash.com/photo-1512036667332-2323862660f9?w=400"},
    {"id": 4, "name": "Con m√®o", "category": "ƒë·ªông v·∫≠t", "type": "video", "url": "https://www.w3schools.com/html/movie.mp4"},
    {"id": 5, "name": "√î t√¥", "category": "giao th√¥ng", "type": "image", "url": "https://images.unsplash.com/photo-1494976388531-d1058494cdd8?w=400"},
]

categories = ["T·∫•t c·∫£", "Gia ƒë√¨nh", "Tr√°i c√¢y", "ƒê·ªì d√πng h·ªçc t·∫≠p", "ƒê·ªông v·∫≠t", "Giao th√¥ng"]

# --- CLASS X·ª¨ L√ù VIDEO V·ªöI AI MEDIAPIPE ---
class HandDetectorProcessor(VideoTransformerBase):
    def __init__(self):
        # Kh·ªüi t·∫°o MediaPipe Hands
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

    def transform(self, frame):
        # Nh·∫≠n di·ªán khung h√¨nh t·ª´ webcam
        img = frame.to_ndarray(format="bgr24")
        
        # L·∫≠t ·∫£nh ƒë·ªÉ ng∆∞·ªùi d√πng d·ªÖ quan s√°t (hi·ªáu ·ª©ng g∆∞∆°ng)
        img = cv2.flip(img, 1)
        
        # Chuy·ªÉn m√†u sang RGB ƒë·ªÉ MediaPipe x·ª≠ l√Ω
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.hands.process(img_rgb)

        # Ki·ªÉm tra n·∫øu ph√°t hi·ªán b√†n tay
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # V·∫Ω c√°c ƒëi·ªÉm n·ªëi v√† kh·ªõp x∆∞∆°ng tay
                self.mp_drawing.draw_landmarks(
                    img, 
                    hand_landmarks, 
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                    self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
                )
            
            # Ghi ch·ªØ th√¥ng b√°o l√™n m√†n h√¨nh video
            cv2.putText(img, "DANG QUET TAY...", (20, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        else:
            cv2.putText(img, "MOI GIO TAY LEN", (20, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return img

# --- GIAO DI·ªÜN STREAMLIT ---
st.title("üëê H·ªá th·ªëng Ng√¥n ng·ªØ K√Ω hi·ªáu AI")

tab1, tab2 = st.tabs(["üìö Th∆∞ vi·ªán h·ªçc t·∫≠p", "üì∑ Nh·∫≠n di·ªán AI"])

# TAB 1: TH∆Ø VI·ªÜN TRA C·ª®U
with tab1:
    col_search, col_display = st.columns([1, 2])
    
    with col_search:
        st.subheader("T√¨m ki·∫øm k√Ω hi·ªáu")
        search_query = st.text_input("Nh·∫≠p t√™n k√Ω hi·ªáu (vd: Qu·∫£ t√°o):")
        cat_filter = st.selectbox("Danh m·ª•c:", categories)
        btn = st.button("Tra c·ª©u")

    with col_display:
        if btn or search_query:
            # L·ªçc d·ªØ li·ªáu d·ª±a tr√™n t√¨m ki·∫øm
            results = [i for i in mock_library if search_query.lower() in i['name'].lower()]
            if results:
                res = results[0]
                st.success(f"K·∫øt qu·∫£: {res['name']}")
                if res['type'] == 'video':
                    st.video(res['url'])
                else:
                    st.image(res['url'], use_container_width=True)
            else:
                st.error("Kh√¥ng t√¨m th·∫•y k√Ω hi·ªáu n√†y trong th∆∞ vi·ªán.")
        else:
            st.info("Vui l√≤ng nh·∫≠p t√™n k√Ω hi·ªáu ƒë·ªÉ xem h√¨nh ·∫£nh/video h∆∞·ªõng d·∫´n.")

# TAB 2: CAMERA NH·∫¨N DI·ªÜN TH·ªúI GIAN TH·ª∞C
with tab2:
    st.subheader("Nh·∫≠n di·ªán c·ª≠ ch·ªâ AI")
    st.write("H√£y nh·∫•n **Start** v√† cho ph√©p truy c·∫≠p Camera. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông qu√©t c√°c ƒëi·ªÉm ƒë·ªët ng√≥n tay c·ªßa b·∫°n.")
    
    # S·ª≠ d·ª•ng WebRTC ƒë·ªÉ x·ª≠ l√Ω video m∆∞·ª£t m√† tr√™n tr√¨nh duy·ªát
    webrtc_streamer(
        key="hand-detection-sign-language",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=HandDetectorProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

st.markdown("---")
st.caption("·ª®ng d·ª•ng ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng Python, Streamlit v√† MediaPipe AI.")
